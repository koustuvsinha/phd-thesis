\begin{table*}[t]
  \centering
  \resizebox{0.9\linewidth}{!}{%
\begin{tabular}{lrrrrrrrl}
\toprule
Model &  QNLI &   RTE &   QQP &  SST-2 &  MRPC &  CoLA &  PAWS &           MNLI (m/mm) \\
\midrule
   OR & 0.925 & 0.746 & 0.913 &  0.939 & 0.892 & 0.614 & 0.945 &  0.861 / 0.854 \\
   R1 & 0.890 & 0.690 & 0.910 &  0.905 & 0.860 & 0.352 & 0.900 &  0.826 / 0.827 \\
   R2 & 0.904 & 0.708 & 0.914 &  0.918 & 0.862 & 0.544 & 0.935 &  0.834 / 0.835 \\
   R3 & 0.917 & 0.707 & 0.912 &  0.920 & 0.864 & 0.487 & 0.940 &  0.838 / 0.838 \\
   R4 & 0.917 & 0.708 & 0.914 &  0.925 & 0.870 & 0.587 & 0.943 &  0.838 / 0.839 \\ \hline
   RC & 0.711 & 0.540 & 0.855 &  0.834 & 0.705 & 0.000 & 0.585 &  0.719 / 0.715 \\
\bottomrule
\end{tabular}}
\caption{GLUE and PAWS dev set results on RoBERTa (base), trained on variants of BookWiki corpus. We use the same evaluation setup of \citet{liu2019b}, and report the median over 5 seeds for the best hyperparam configuration.}
\label{table:glue}
\end{table*}
