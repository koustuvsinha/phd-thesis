@inproceedings{Clark2020TransformersAS,
  title           = {Transformers as Soft Reasoners over Language},
  author          = {Peter Clark and Oyvind Tafjord and Kyle Richardson},
  booktitle       = {IJCAI},
  year            = 2020
}

@article{Cloutre2021DemystifyingNL,
  title           = {Demystifying Neural Language Models' Insensitivity to
                  Word-Order},
  author          = {Louis Clou{\^a}tre and Prasanna Parthasarathi and Amal
                  Zouaq and Sarath Chandar},
  journal         = {ArXiv},
  year            = 2021,
  volume          = {abs/2107.13955}
}

@inproceedings{Malkin2021StudyingWO,
  title           = {Studying word order through iterative shuffling},
  author          = {Nikolay Malkin and Sameera Lanka and Pranav Goel and
                  Nebojsa Jojic},
  booktitle       = {EMNLP},
  year            = 2021
}

@article{Ontan2022LogicInferenceAN,
  title           = {LogicInference: A New Dataset for Teaching Logical
                  Inference to seq2seq Models},
  author          = {Santiago Onta{\~n}{\'o}n and Joshua Ainslie and Vaclav
                  Cvicek and Zachary Kenneth Fisher},
  journal         = {ArXiv},
  year            = 2022,
  volume          = {abs/2203.15099}
}

@inproceedings{Perez2021RissanenDA,
  title           = {Rissanen Data Analysis: Examining Dataset Characteristics
                  via Description Length},
  author          = {Ethan Perez and Douwe Kiela and Kyunghyun Cho},
  booktitle       = {ICML},
  year            = 2021
}

@article{Tejankar2021AFO,
  title           = {A Fistful of Words: Learning Transferable Visual Models
                  from Bag-of-Words Supervision},
  author          = {Ajinkya Tejankar and Bichen Wu and Saining Xie and Madian
                  Khabsa and Hamed Pirsiavash and Hamed Firooz},
  journal         = {ArXiv},
  year            = 2021,
  volume          = {abs/2112.13884}
}

@article{Zhang2022OnTP,
  title           = {On the Paradox of Learning to Reason from Data},
  author          = {Honghua Zhang and Liunian Harold Li and Tao Meng and
                  Kai-Wei Chang and Guy Van den Broeck},
  journal         = {ArXiv},
  year            = 2022,
  volume          = {abs/2205.11502}
}

@inproceedings{clouatre-etal-2022-local,
  title           = "Local Structure Matters Most: Perturbation Study in {NLU}",
  author          = "Clouatre, Louis and Parthasarathi, Prasanna and Zouaq, Amal
                  and Chandar, Sarath",
  booktitle       = "Findings of the Association for Computational Linguistics:
                  ACL 2022",
  month           = may,
  year            = 2022,
  address         = "Dublin, Ireland",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2022.findings-acl.293",
  doi             = "10.18653/v1/2022.findings-acl.293",
  pages           = "3712--3731",
  abstract        = "Recent research analyzing the sensitivity of natural
                  language understanding models to word-order perturbations has
                  shown that neural models are surprisingly insensitive to the
                  order of words.In this paper, we investigate this phenomenon
                  by developing order-altering perturbations on the order of
                  words, subwords, and characters to analyze their effect on
                  neural models{'} performance on language understanding
                  tasks.We experiment with measuring the impact of perturbations
                  to the local neighborhood of characters and global position of
                  characters in the perturbed texts and observe that
                  perturbation functions found in prior literature only affect
                  the global ordering while the local ordering remains
                  relatively unperturbed.We empirically show that neural models,
                  invariant of their inductive biases, pretraining scheme, or
                  the choice of tokenization, mostly rely on the local structure
                  of text to build understanding and make limited use of the
                  global structure.",
}

@inproceedings{fei-etal-2022-cqg,
  title           = "{CQG}: A Simple and Effective Controlled Generation
                  Framework for Multi-hop Question Generation",
  author          = "Fei, Zichu and Zhang, Qi and Gui, Tao and Liang, Di and
                  Wang, Sirui and Wu, Wei and Huang, Xuanjing",
  booktitle       = "Proceedings of the 60th Annual Meeting of the Association
                  for Computational Linguistics (Volume 1: Long Papers)",
  month           = may,
  year            = 2022,
  address         = "Dublin, Ireland",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2022.acl-long.475",
  doi             = "10.18653/v1/2022.acl-long.475",
  pages           = "6896--6906",
  abstract        = "Multi-hop question generation focuses on generating complex
                  questions that require reasoning over multiple pieces of
                  information of the input passage. Current models with
                  state-of-the-art performance have been able to generate the
                  correct questions corresponding to the answers. However, most
                  models can not ensure the complexity of generated questions,
                  so they may generate shallow questions that can be answered
                  without multi-hop reasoning. To address this challenge, we
                  propose the CQG, which is a simple and effective controlled
                  framework. CQG employs a simple method to generate the
                  multi-hop questions that contain key entities in multi-hop
                  reasoning chains, which ensure the complexity and quality of
                  the questions. In addition, we introduce a novel controlled
                  Transformer-based decoder to guarantee that key entities
                  appear in the questions. Experiment results show that our
                  model greatly improves performance, which also outperforms the
                  state-of-the-art model about 25{\%} by 5 BLEU points on
                  HotpotQA.",
}

@article{gontier2020measuring,
  title           = {Measuring systematic generalization in neural proof
                  generation with transformers},
  author          = {Gontier, Nicolas and Sinha, Koustuv and Reddy, Siva and
                  Pal, Chris},
  journal         = {Advances in Neural Information Processing Systems},
  volume          = 33,
  pages           = {22231--22242},
  year            = 2020
}

@inproceedings{goodwin-etal-2020-probing,
  title           = "Probing Linguistic Systematicity",
  author          = "Goodwin, Emily and Sinha, Koustuv and O{'}Donnell, Timothy
                  J.",
  booktitle       = "Proceedings of the 58th Annual Meeting of the Association
                  for Computational Linguistics",
  month           = jul,
  year            = 2020,
  address         = "Online",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2020.acl-main.177",
  doi             = "10.18653/v1/2020.acl-main.177",
  pages           = "1958--1969",
  abstract        = "Recently, there has been much interest in the question of
                  whether deep natural language understanding (NLU) models
                  exhibit systematicity, generalizing such that units like words
                  make consistent contributions to the meaning of the sentences
                  in which they appear. There is accumulating evidence that
                  neural models do not learn systematically. We examine the
                  notion of systematicity from a linguistic perspective,
                  defining a set of probing tasks and a set of metrics to
                  measure systematic behaviour. We also identify ways in which
                  network architectures can generalize non-systematically, and
                  discuss why such forms of generalization may be unsatisfying.
                  As a case study, we perform a series of experiments in the
                  setting of natural language inference (NLI). We provide
                  evidence that current state-of-the-art NLU systems do not
                  generalize systematically, despite overall high performance.",
}

@inproceedings{hessel-schofield-2021-effective,
  title           = "How effective is {BERT} without word ordering? Implications
                  for language understanding and data privacy",
  author          = "Hessel, Jack and Schofield, Alexandra",
  booktitle       = "Proceedings of the 59th Annual Meeting of the Association
                  for Computational Linguistics and the 11th International Joint
                  Conference on Natural Language Processing (Volume 2: Short
                  Papers)",
  month           = aug,
  year            = 2021,
  address         = "Online",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2021.acl-short.27",
  doi             = "10.18653/v1/2021.acl-short.27",
  pages           = "204--211",
  abstract        = "Ordered word sequences contain the rich structures that
                  define language. However, it{'}s often not clear if or how
                  modern pretrained language models utilize these structures. We
                  show that the token representations and self-attention
                  activations within BERT are surprisingly resilient to
                  shuffling the order of input tokens, and that for several GLUE
                  language understanding tasks, shuffling only minimally
                  degrades performance, e.g., by 4{\%} for QNLI. While bleak
                  from the perspective of language understanding, our results
                  have positive implications for cases where copyright or ethics
                  necessitates the consideration of bag-of-words data (vs. full
                  documents). We simulate such a scenario for three sensitive
                  classification tasks, demonstrating minimal performance
                  degradation vs. releasing full language sequences.",
}

@inproceedings{minervini2020learning,
  title           = {Learning reasoning strategies in end-to-end differentiable
                  proving},
  author          = {Minervini, Pasquale and Riedel, Sebastian and Stenetorp,
                  Pontus and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle       = {International Conference on Machine Learning},
  pages           = {6938--6949},
  year            = 2020,
  organization    = {PMLR}
}

@inproceedings{tamari-etal-2022-dyna,
  title           = "{D}yna-b{A}b{I}: unlocking b{A}b{I}{'}s potential with
                  dynamic synthetic benchmarking",
  author          = "Tamari, Ronen and Richardson, Kyle and Kahlon, Noam and
                  Sar-shalom, Aviad and Liu, Nelson F. and Tsarfaty, Reut and
                  Shahaf, Dafna",
  booktitle       = "Proceedings of the 11th Joint Conference on Lexical and
                  Computational Semantics",
  month           = jul,
  year            = 2022,
  address         = "Seattle, Washington",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2022.starsem-1.9",
  pages           = "101--122",
  abstract        = "While neural language models often perform surprisingly
                  well on natural language understanding (NLU) tasks, their
                  strengths and limitations remain poorly understood. Controlled
                  synthetic tasks are thus an increasingly important resource
                  for diagnosing model behavior. In this work we focus on story
                  understanding, a core competency for NLU systems. However, the
                  main synthetic resource for story understanding, the bAbI
                  benchmark, lacks such a systematic mechanism for controllable
                  task generation. We develop Dyna-bAbI, a dynamic framework
                  providing fine-grained control over task generation in bAbI.
                  We demonstrate our ideas by constructing three new tasks
                  requiring compositional generalization, an important
                  evaluation setting absent from the original benchmark. We
                  tested both special-purpose models developed for bAbI as well
                  as state-of-the-art pre-trained methods, and found that while
                  both approaches solve the original tasks (99{{\%} accuracy),
                  neither approach succeeded in the compositional generalization
                  setting, indicating the limitations of the original training
                  data.We explored ways to augment the original data, and found
                  that though diversifying training data was far more useful
                  than simply increasing dataset size, it was still insufficient
                  for driving robust compositional generalization (with 70{{\%}
                  accuracy for complex compositions). Our results underscore the
                  importance of highly controllable task generators for creating
                  robust NLU systems through a virtuous cycle of model and data
                  development.",
}

@inproceedings{tian-etal-2021-diagnosing,
  title           = "Diagnosing the First-Order Logical Reasoning Ability
                  Through {L}ogic{NLI}",
  author          = "Tian, Jidong and Li, Yitian and Chen, Wenqing and Xiao,
                  Liqiang and He, Hao and Jin, Yaohui",
  booktitle       = "Proceedings of the 2021 Conference on Empirical Methods in
                  Natural Language Processing",
  month           = nov,
  year            = 2021,
  address         = "Online and Punta Cana, Dominican Republic",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2021.emnlp-main.303",
  doi             = "10.18653/v1/2021.emnlp-main.303",
  pages           = "3738--3747",
  abstract        = "Recently, language models (LMs) have achieved significant
                  performance on many NLU tasks, which has spurred widespread
                  interest for their possible applications in the scientific and
                  social area. However, LMs have faced much criticism of whether
                  they are truly capable of reasoning in NLU. In this work, we
                  propose a diagnostic method for first-order logic (FOL)
                  reasoning with a new proposed benchmark, LogicNLI. LogicNLI is
                  an NLI-style dataset that effectively disentangles the target
                  FOL reasoning from commonsense inference and can be used to
                  diagnose LMs from four perspectives: accuracy, robustness,
                  generalization, and interpretability. Experiments on BERT,
                  RoBERTa, and XLNet, have uncovered the weaknesses of these LMs
                  on FOL reasoning, which motivates future exploration to
                  enhance the reasoning ability.",
}

@inproceedings{webson-pavlick-2022-prompt,
  title           = "Do Prompt-Based Models Really Understand the Meaning of
                  Their Prompts?",
  author          = "Webson, Albert and Pavlick, Ellie",
  booktitle       = "Proceedings of the 2022 Conference of the North American
                  Chapter of the Association for Computational Linguistics:
                  Human Language Technologies",
  month           = jul,
  year            = 2022,
  address         = "Seattle, United States",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2022.naacl-main.167",
  pages           = "2300--2344",
}

@article{weston2015towardsai,
  title           = {Towards ai-complete question answering: A set of
                  prerequisite toy tasks},
  author          = {Weston, Jason and Bordes, Antoine and Chopra, Sumit and
                  Rush, Alexander M and Van Merri{\"e}nboer, Bart and Joulin,
                  Armand and Mikolov, Tomas},
  journal         = {arXiv preprint arXiv:1502.05698},
  year            = 2015
}

@inproceedings{yanaka-etal-2021-sygns,
  title           = "{S}y{GNS}: A Systematic Generalization Testbed Based on
                  Natural Language Semantics",
  author          = "Yanaka, Hitomi and Mineshima, Koji and Inui, Kentaro",
  booktitle       = "Findings of the Association for Computational Linguistics:
                  ACL-IJCNLP 2021",
  month           = aug,
  year            = 2021,
  address         = "Online",
  publisher       = "Association for Computational Linguistics",
  url             = "https://aclanthology.org/2021.findings-acl.10",
  doi             = "10.18653/v1/2021.findings-acl.10",
  pages           = "103--119",
}
