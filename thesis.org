#+title: PhD Thesis
#+SETUPFILE:mcgill_thesis.org
#+OPTIONS: toc:nil date:nil
#+bibliography: /Users/koustuvs/Documents/mylibrefs_new.bib

#+latex: \raggedbottom
#+latex: \spacing{1.5}%\onehalfspacing
#+latex: \pagenumbering{roman}

* Acknowledgements
:PROPERTIES:
:UNNUMBERED: notoc
:END:
* Abstract
:PROPERTIES:
:UNNUMBERED: notoc
:END:
* Abstract in French
:PROPERTIES:
:UNNUMBERED: notoc
:END:
* Contributions to Original Knowledge
:PROPERTIES:
:UNNUMBERED: notoc
:END:
* Contributions of Authors
:PROPERTIES:
:UNNUMBERED: notoc
:END:

#+latex: \listoffigures{}

* List of Tables
:PROPERTIES:
:UNNUMBERED: notoc
:END:

#+latex: \clearpage
#+TOC: headlines 3

#+latex: \clearpage

#+latex: \pagenumbering{arabic}
* Introduction
:PROPERTIES:
:tags: newpage
:END:


**Central Theme of the thesis** : Understanding systematicity in pre-trained language models through semantic and syntactic generalization.

In this thesis I discuss my work on understanding systematicity in pre-trained language models.

#+latex: \clearpage
* Background

#+name: glossary
| label | name         | description                                            |
|-------+--------------+--------------------------------------------------------|
| tlm   | Transformers | A class of models first derived by Vaswani et al. 2017 |

#+name: acronyms
| Key | Short | Long                  |
|-----+-------+-----------------------|
| llm | LLMs  | Large Language Models |
| qos | QoS   | quality-of-service    |
| bb  | BB    | branch and bound      |

** Early methods for text representation
** Neural Inductive bias of text representation
*** Feed Forward Neural Networks
*** Recurrent Neural Networks
*** Transformer Models

ac:llm are the state-of-the-art in language models, which are based on gls:tlm.
** Pre-training and the advent of Large Language Models
Success of pre-training and scale
** Systematicity and Generalization
*** Definitions
**** Productivity
**** Word Order Sensitivity
*** Tasks
#+latex: \clearpage
* Understanding semantic generalization through productivity

** Technical Background
** CLUTRR: A Diagnostic Benchmark for Inductive Reasoning in Text

Paper: cite:sinha2019a

*** Dataset construction

#+ATTR_LATEX: :height 0.3\textwidth
#+CAPTION: Dataset generation pipeline.
[[file:figs/clutrr/dataset_const_proof.png]]

#+ATTR_LATEX: :height 0.3\textwidth
#+CAPTION: Illustration of how a set of facts can split and combined in various ways across sentences.
[[file:figs/clutrr/composition.png]]

#+ATTR_LATEX: :height 0.3\textwidth
#+CAPTION: Noise generation procedures of CLUTRR.
[[file:figs/clutrr/clutrr_noise.png]]

*** Productivity and reasoning
** Results

#+begin_center
#+ATTR_LATEX: :height 0.3\textwidth :center nil
[[file:figs/clutrr/emnlp/sys_gen_23.pdf]]
#+ATTR_LATEX: :height 0.3\textwidth :center nil
[[file:figs/clutrr/emnlp/sys_gen_234.pdf]]
#+end_center
#+CAPTION: Systematic generalization when train on k=$2$ and $3$.
#+ATTR_LATEX: :height 0.0001in
[[file:figs/empy_fig.png]]


** Related Work
** Discussion
** Follow-up findings in the community
#+latex: \clearpage
* Quantifying syntactic generalization using word order

Paper cite:sinha2021a

** Technical Background
** Word Order in Natural Language Inference
*** Probe Construction

#+ATTR_LATEX: :height 0.3\textwidth
#+CAPTION: Graphical representation of the Permutation Acceptance class of metrics.
[[file:figs/unli/nli_gen_perm_desc.pdf]]

** Experiments & Results

#+CAPTION: Comparison of $\omega_{\text{max}}$, $\omega_{\text{rand}}$, $\mathcal{P}^{c}$ and $\mathcal{P}^{f}$ with the model accuracy $\mathcal{A}$ on multiple datasets, where all models are trained on the MNLI corpus cite:williams-etal-2018-broad.
[[file:figs/unli/comb_plot_all.pdf]]

#+CAPTION: Average entropy of model confidences on permutations..
[[file:figs/unli/all_entropy.png]]

#+CAPTION: BLEU-2 score versus acceptability of permuted sentences across all test datasets.
[[file:figs/unli/bleu_2_all.png]]

#+CAPTION: POS Tag Mini-Tree overlap score and percentage of permutations which the models assigned the gold label.
[[file:figs/unli/min_tree_4.png]]

#+CAPTION: $\omega_{x}$ threshold for all datasets with varying $x$ and computing the percentage of examples that fall within the threshold.
[[file:figs/unli/omega_threshold.png]]



** Related Work
** Discussion
** Follow-up findings in the community

#+latex: \clearpage
* Probing syntax understanding through distributional hypothesis

Paper: cite:sinha2021

** Technical Background
** Dataset construction and pre-training
** Experiments
*** Downstream reasoning tasks

#+CAPTION: Downstream results on scrambled pre-training.
[[file:figs/unnat_pt/main_result_plot.pdf]]

#+CAPTION: GLUE and PAWS task dev set performance when finetuned on naturally and randomly ordered text, respectively, using pre-trained RoBERTa (base) models on different versions of BookWiki corpus.
[[file:figs/unnat_pt/finetune_rand.pdf]]

*** Evaluating the effectiveness of probing syntax

#+CAPTION: Risannen Data Analysis.
[[file:figs/unnat_pt/rda_mdl_ep_3.pdf]]

** Related Work
** Discussion
** Follow-up findings in the community
#+latex: \clearpage
* Measuring systematic generalization by exploiting absolute positions

** Technical Background
** Systematic understanding of absolute position embeddings
** Related Work
** Experiments

#+CAPTION: Grammatical acceptability scores on BLiMP dataset.
[[file:figs/pos_enc/acceptability_scores.pdf]]

** Discussion
#+latex: \clearpage
* Conclusion
** Summary
** Limitations
** Future Work
#+latex: \clearpage
* Bibliography
bibliographystyle:unsrt
bibliography:/Users/koustuvs/Documents/mylibrefs_new.bib,bibfiles/unli.bib,bibfiles/clutrr.bib,bibfiles/pos_enc.bib,bibfiles/unnat_pt.bib,bibfiles/anthology.bib


#+latex: \printglossaries

* Appendix
** Org mode auto save
Run the following snippet to auto save and compile in org mode.

#+begin_src elisp
(defun kdm/org-save-and-export ()
(interactive)
(if (and (eq major-mode 'org-mode)
    (ido-local-file-exists-p (concat (file-name-sans-extension (buffer-name)) ".tex")))
  (org-latex-export-to-latex)))

(add-hook 'after-save-hook 'kdm/org-save-and-export)
#+end_src

#+RESULTS:
| kdm/org-save-and-export | doom-modeline-update-vcs-text | doom-modeline-update-vcs-icon | doom-modeline-update-buffer-file-name | rmail-after-save-hook | +evil-display-vimlike-save-message-h | doom-auto-revert-buffers-h | doom-guess-mode-h |

** Remove "parts" from report

#+begin_src elisp
(add-to-list 'org-latex-classes
             '("report-noparts"
               "\\documentclass[11pt]{report}"
               ("\\chapter{%s}" . "\\chapter*{%s}")
               ("\\section{%s}" . "\\section*{%s}")
               ("\\subsection{%s}" . "\\subsection*{%s}")
               ("\\subsubsection{%s}" . "\\subsubsection*{%s}")))
#+end_src
** Add newpage before a heading

#+begin_src elisp
(defun org/get-headline-string-element  (headline backend info)
  (let ((prop-point (next-property-change 0 headline)))
    (if prop-point (plist-get (text-properties-at prop-point headline) :parent))))

(defun org/ensure-latex-clearpage (headline backend info)
  (when (org-export-derived-backend-p backend 'latex)
    (let ((elmnt (org/get-headline-string-element headline backend info)))
      (when (member "newpage" (org-element-property :tags elmnt))
        (concat "\\clearpage\n" headline)))))

(add-to-list 'org-export-filter-headline-functions
             'org/ensure-latex-clearpage)

#+end_src

#+RESULTS:
| org/ensure-latex-clearpage |

** Glossary and Acronym build using Latexmk

Add the following snippet in the file "~/.latexmkrc": (Source: https://tex.stackexchange.com/a/44316)

#+begin_src bash
add_cus_dep('glo', 'gls', 0, 'run_makeglossaries');
add_cus_dep('acn', 'acr', 0, 'run_makeglossaries');

sub run_makeglossaries {
    my ($base_name, $path) = fileparse( $_[0] ); #handle -outdir param by splitting path and file, ...
    pushd $path; # ... cd-ing into folder first, then running makeglossaries ...

    if ( $silent ) {
        system "makeglossaries -q '$base_name'"; #unix
        # system "makeglossaries", "-q", "$base_name"; #windows
    }
    else {
        system "makeglossaries '$base_name'"; #unix
        # system "makeglossaries", "$base_name"; #windows
    };

    popd; # ... and cd-ing back again
}

push @generated_exts, 'glo', 'gls', 'glg';
push @generated_exts, 'acn', 'acr', 'alg';
$clean_ext .= ' %R.ist %R.xdy';
#+end_src
** Citation style buffer local

#+begin_src elisp
(set (make-local-variable 'bibtex-completion-format-citation-functions)
  '((org-mode      . my/bibtex-completion-format-citation-org-default-cite)))
#+end_src

#+RESULTS:
: ((org-mode . my/bibtex-completion-format-citation-org-default-cite))
** Org latex compiler options

#+begin_src elisp
(setq org-latex-pdf-process (list "latexmk -f -pdf -%latex -interaction=nonstopmode -output-directory=%o %f"))
#+end_src

Original value

#+begin_src elisp
(setq org-latex-pdf-process (list "latexmk -f -pdf %f"))
#+end_src

#+RESULTS:
| latexmk -f -pdf %f |

Let us try Fast compile https://gist.github.com/yig/ba124dfbc8f63762f222.

#+begin_src elisp
(setq org-latex-pdf-process (list "latexmk-fast %f"))
#+end_src

#+RESULTS:
| latexmk-fast %f |

- Doesn't seem to work from Emacs.
- I need to change the save function to only export in tex. Then, have a separate process run latexmk.
- Using the python package =when-changed= to watch the thesis.tex file for change.
- Usage:

#+begin_src bash
when-changed thesis.tex latexmk -f -pdf -interaction=nonstopmode -output-directory=%o thesis.tex
#+end_src

- The pdf does not update. It seems to but not always? No it does. For some reason, compilation takes ages.
- Works with =when-changed=!
